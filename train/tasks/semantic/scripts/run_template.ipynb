{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "experiment_name=\"\"\n",
    "experiment_version=\"\"\n",
    "commit_message=\"\"\n",
    "working_dir = \"\"\n",
    "dataset=\"\"\n",
    "arch_cfg=\"\"\n",
    "data_cfg=\"\"\n",
    "log = \"\"\n",
    "pretrained=None\n",
    "use_cross_validation=0\n",
    "num_cross_folds=0\n",
    "cuda=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(working_dir, dataset, arch_cfg, data_cfg, log, pretrained, use_cross_validation, num_cross_folds,cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mrafaat/AliThesis/lidar-bonnetal/train/tasks/semantic/logs/filtered-semantic-test/test/2020-08-14-21:34:17\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=7\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=$cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "/home/mrafaat/AliThesis/lidar-bonnetal/train/tasks/semantic\n",
      "----------\n",
      "INTERFACE:\n",
      "dataset /raid/ali/AliThesis/FilteredSemanticKitti/dataset/\n",
      "arch_cfg /home/mrafaat/AliThesis/lidar-bonnetal/train/tasks/semantic/config/filtered-semantic/arch/squeezesegV2_crf-early.yaml\n",
      "data_cfg /home/mrafaat/AliThesis/lidar-bonnetal/train/tasks/semantic/config/filtered-semantic/labels/filtered-semantic.yaml\n",
      "log /home/mrafaat/AliThesis/lidar-bonnetal/train/tasks/semantic/logs/filtered-semantic-test/test/2020-08-14-21:34:17\n",
      "pretrained None\n",
      "----------\n",
      "\n",
      "Commit hash (training version):  b'3185644'\n",
      "----------\n",
      "\n",
      "Opening arch config file /home/mrafaat/AliThesis/lidar-bonnetal/train/tasks/semantic/config/filtered-semantic/arch/squeezesegV2_crf-early.yaml\n",
      "Opening data config file /home/mrafaat/AliThesis/lidar-bonnetal/train/tasks/semantic/config/filtered-semantic/labels/filtered-semantic.yaml\n",
      "model folder doesnt exist! Start with random weights...\n",
      "Copying files to /home/mrafaat/AliThesis/lidar-bonnetal/train/tasks/semantic/logs/filtered-semantic-test/test/2020-08-14-21:34:17 for further reference.\n",
      "0\n",
      "using seed 90\n",
      "Sequences folder exists! Using sequences from /raid/ali/AliThesis/FilteredSemanticKitti/dataset/sequences\n",
      "parsing seq 00\n",
      "parsing seq 02\n",
      "parsing seq 03\n",
      "parsing seq 04\n",
      "parsing seq 05\n",
      "parsing seq 06\n",
      "parsing seq 09\n",
      "parsing seq 10\n",
      "Using 16928 scans from sequences [0, 2, 3, 4, 5, 6, 9, 10]\n",
      "Sequences folder exists! Using sequences from /raid/ali/AliThesis/FilteredSemanticKitti/dataset/sequences\n",
      "parsing seq 01\n",
      "parsing seq 07\n",
      "Using 2202 scans from sequences [1, 7]\n",
      "Loss weights from content:  tensor([  0.0000,  18.9185, 892.7044, 694.5958, 297.7805, 271.4942, 715.1933,\n",
      "        818.3459, 808.7357,   3.6022,  72.2475,   7.7669, 300.6005,  10.6206,\n",
      "         14.7247,   3.9977, 118.3736,  15.8893, 222.3522, 591.8877])\n",
      "Using SqueezeNet Backbone\n",
      "Depth of backbone input =  8\n",
      "Original OS:  16\n",
      "New OS:  16\n",
      "Strides:  [2, 2, 2, 2]\n",
      "Decoder original OS:  16\n",
      "Decoder new OS:  16\n",
      "Decoder strides:  [2, 2, 2, 2]\n",
      "Using CRF!\n",
      "Total number of parameters:  930809\n",
      "Total number of parameters requires_grad:  930804\n",
      "Param encoder  737596\n",
      "Param decoder  181248\n",
      "Param head  11540\n",
      "Param CRF  425\n",
      "\n",
      "Couldn't load backbone, using random weights. Error:  [Errno 2] No such file or directory: 'None/backbone'\n",
      "Couldn't load decoder, using random weights. Error:  [Errno 2] No such file or directory: 'None/segmentation_decoder'\n",
      "Couldn't load head, using random weights. Error:  [Errno 2] No such file or directory: 'None/segmentation_head'\n",
      "Couldn't load CRF, using random weights. Error:  [Errno 2] No such file or directory: 'None/segmentation_CRF'\n",
      "Training in device:  cuda\n",
      "Ignoring class  0  in IoU evaluation\n",
      "[IOU EVAL] IGNORE:  tensor([0])\n",
      "[IOU EVAL] INCLUDE:  tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19])\n",
      "Lr: 0.000e+00 | Update: 2.271e-07 mean,6.766e-07 std | Epoch: [0][0/1058] | Time 1.833 (1.833) | Data 0.652 (0.652) | Loss 2.9735 (2.9735) | acc 0.000 (0.000) | IoU 0.000 (0.000)\n",
      "Lr: 5.000e-04 | Update: 3.392e-02 mean,6.453e-02 std | Epoch: [0][5/1058] | Time 0.362 (0.606) | Data 0.023 (0.127) | Loss 2.9872 (2.9826) | acc 0.000 (0.000) | IoU 0.000 (0.000)\n",
      "Lr: 1.000e-03 | Update: 1.767e-02 mean,3.436e-02 std | Epoch: [0][10/1058] | Time 0.358 (0.493) | Data 0.021 (0.079) | Loss 3.0232 (2.9817) | acc 0.000 (0.000) | IoU 0.000 (0.000)\n",
      "Lr: 1.000e-03 | Update: 9.580e-03 mean,1.831e-02 std | Epoch: [0][15/1058] | Time 0.384 (0.455) | Data 0.038 (0.064) | Loss 2.9504 (2.9791) | acc 0.000 (0.000) | IoU 0.000 (0.000)\n",
      "Lr: 9.999e-04 | Update: 8.908e-03 mean,1.719e-02 std | Epoch: [0][20/1058] | Time 0.362 (0.433) | Data 0.024 (0.055) | Loss 2.9621 (2.9799) | acc 0.001 (0.000) | IoU 0.000 (0.000)\n",
      "Lr: 9.999e-04 | Update: 5.867e-03 mean,1.150e-02 std | Epoch: [0][25/1058] | Time 0.364 (0.419) | Data 0.028 (0.049) | Loss 2.9849 (2.9781) | acc 0.002 (0.001) | IoU 0.000 (0.000)\n",
      "Lr: 9.998e-04 | Update: 5.222e-03 mean,1.022e-02 std | Epoch: [0][30/1058] | Time 0.354 (0.409) | Data 0.019 (0.044) | Loss 2.9735 (2.9775) | acc 0.039 (0.004) | IoU 0.006 (0.001)\n",
      "Lr: 9.998e-04 | Update: 4.648e-03 mean,9.076e-03 std | Epoch: [0][35/1058] | Time 0.359 (0.401) | Data 0.023 (0.041) | Loss 2.9607 (2.9774) | acc 0.154 (0.016) | IoU 0.015 (0.002)\n",
      "Lr: 9.997e-04 | Update: 4.681e-03 mean,9.078e-03 std | Epoch: [0][40/1058] | Time 0.361 (0.397) | Data 0.025 (0.040) | Loss 2.9410 (2.9772) | acc 0.221 (0.038) | IoU 0.017 (0.004)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 132, in <module>\n",
      "    trainer.train()\n",
      "  File \"../../tasks/semantic/modules/trainer.py\", line 251, in train\n",
      "    show_scans=self.ARCH[\"train\"][\"show_scans\"])\n",
      "  File \"../../tasks/semantic/modules/trainer.py\", line 348, in train_epoch\n",
      "    output = model(in_vol, proj_mask)\n",
      "  File \"/home/mrafaat/anaconda3/envs/ali_thesis/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"../../tasks/semantic/modules/segmentator.py\", line 167, in forward\n",
      "    y, skips = self.backbone(x)  \n",
      "  File \"/home/mrafaat/anaconda3/envs/ali_thesis/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"../..//backbones/squeezesegV2.py\", line 181, in forward\n",
      "    x, skips, os = self.run_layer(x, self.fire23, skips, os)\n",
      "  File \"../..//backbones/squeezesegV2.py\", line 158, in run_layer\n",
      "    y = layer(x)\n",
      "  File \"/home/mrafaat/anaconda3/envs/ali_thesis/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/mrafaat/anaconda3/envs/ali_thesis/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/mrafaat/anaconda3/envs/ali_thesis/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"../..//backbones/squeezesegV2.py\", line 27, in forward\n",
      "    x = self.activation(self.squeeze_bn(self.squeeze(x)))\n",
      "  File \"/home/mrafaat/anaconda3/envs/ali_thesis/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/mrafaat/anaconda3/envs/ali_thesis/lib/python3.6/site-packages/torch/nn/modules/activation.py\", line 99, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "  File \"/home/mrafaat/anaconda3/envs/ali_thesis/lib/python3.6/site-packages/torch/nn/functional.py\", line 941, in relu\n",
      "    result = torch.relu_(input)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!echo \"${CUDA_VISIBLE_DEVICES}\"\n",
    "%cd $working_dir\n",
    "!python train.py --dataset $dataset --arch_cfg $arch_cfg --data_cfg $data_cfg --log $log --pretrained $pretrained --use_cross_validation $use_cross_validation --num_cross_folds $num_cross_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.check_output(\"git checkout dev\", shell=True)\n",
    "subprocess.check_output(f\"git checkout {experiment_name} || git checkout -b {experiment_name}\", shell=True)\n",
    "subprocess.check_output(f\"git add {log}\", shell=True)\n",
    "subprocess.check_output(f\"git commit -m \\\"{commit_message}\\\"\", shell=True)\n",
    "subprocess.check_output(f\"git tag {experiment_version}\", shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
